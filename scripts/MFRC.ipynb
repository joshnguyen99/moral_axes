{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4acd055",
   "metadata": {},
   "source": [
    "# Moral foudations Redidt corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1388d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Package pickle5 becomes unnecessary in Python 3.8 and above. Its presence may confuse libraries including Ray. Please uninstall the package.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import ast\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import sklearn\n",
    "import os\n",
    "import swifter\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c06f455",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e527f7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>bucket</th>\n",
       "      <th>annotator</th>\n",
       "      <th>annotation</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That particular part of the debate is especial...</td>\n",
       "      <td>europe</td>\n",
       "      <td>French politics</td>\n",
       "      <td>annotator03</td>\n",
       "      <td>Non-Moral</td>\n",
       "      <td>Confident</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text subreddit  \\\n",
       "0  That particular part of the debate is especial...    europe   \n",
       "\n",
       "            bucket    annotator annotation confidence  \n",
       "0  French politics  annotator03  Non-Moral  Confident  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfrc = pd.read_csv(\"data/MFRC/final_mfrc_data.csv\")\n",
    "mfrc.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c963f97",
   "metadata": {},
   "source": [
    "- Make sentences unique\n",
    "- Map moral domains to MFD (needs double-checking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78e1a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.corpus import stopwords\n",
    "nltk_stopwords = stopwords.words('english')\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "stopwords = set(list(nltk_stopwords) + list(ENGLISH_STOP_WORDS) + list(STOP_WORDS))\n",
    "\n",
    "def preprocess(texts, progress_bar=False):\n",
    "    input_type = type(texts)\n",
    "    if input_type == str: texts = [texts]\n",
    "    tokens = []\n",
    "    for doc in tqdm(nlp.pipe(texts, n_process=1), \n",
    "                    desc=\"Processed\", disable=not progress_bar, \n",
    "                    dynamic_ncols=True, unit=\" docs\"):\n",
    "        tokens_df = [[tok.text, tok.ent_type_, tok.tag_] for tok in doc]\n",
    "        tokens_df = pd.DataFrame(tokens_df, columns=[\"token\", \"entity\", \"pos\"])\n",
    "        \n",
    "        # Remove entities\n",
    "        tokens_df = tokens_df[tokens_df.entity == \"\"]\n",
    "        \n",
    "        # Filter POS tags\n",
    "        keep_pos = ['NN','NNS','JJ','VB','VBD','VBG','VBN','VBP','VBZ','RB']\n",
    "        tokens_df = tokens_df[tokens_df.pos.isin(keep_pos)]\n",
    "        \n",
    "        # Remove bad characters\n",
    "        no_chars = [\"…\",\"'ve\",\"'s\",\"'ll\",\"'d\",\"\\\"\",\"'m\",\"'s\",\"'re\",\"–-\",'–-', '‘', '’d',\n",
    "                    '’ll', '’m', '’re', '’s', '’ve', '“', ',,',',','(',')','.', '”', '\\n\\n',\n",
    "                    \"@realDonaldTrump\",\"n't\",'\\xad']\n",
    "        tokens_df = tokens_df[tokens_df.pos.isin(keep_pos)]\n",
    "        \n",
    "        # Remove stop words\n",
    "        tokens_df = tokens_df[np.logical_not(tokens_df.token.isin(list(stopwords)))]\n",
    "        \n",
    "        # Remove non-alphabetic characters from each token\n",
    "        tokens_df[\"token\"] = tokens_df.token.apply(lambda x: \"\".join(filter(lambda c: c.isalpha(), x)))\n",
    "        \n",
    "        # Keep tokens with at least 3 characters\n",
    "        tokens_df = tokens_df[tokens_df.token.apply(len) >= 3]\n",
    "        \n",
    "        # Lowercase tokens\n",
    "        tokens_df[\"token\"] = tokens_df.token.apply(str.lower)\n",
    "    \n",
    "        tokens.append(tokens_df.token.values.tolist())\n",
    "    \n",
    "    if input_type == str:\n",
    "        return tokens[0]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de808d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"data/corpora/MFRC_AITA_tokenized.csv\"):\n",
    "    mfrc_unique = pd.DataFrame()\n",
    "    mfrc_unique[\"text\"] = mfrc.text.unique()\n",
    "    # Preprocess and tokenize\n",
    "    mfrc_unique[\"tokens\"] = mfrc_unique[\"text\"].map(preprocess)\n",
    "    \n",
    "    for i in [\"authority\", \"care\", \"fairness\", \"loyalty\", \"sanctity\", \"none\"]:\n",
    "        mfrc_unique[i] = 0\n",
    "    mfrc_unique.set_index(\"text\", inplace=True)\n",
    "\n",
    "    key_map = {\n",
    "        \"Thin Morality\": \"none\",\n",
    "        \"Non-Moral\": \"none\",\n",
    "        \"Care\": \"care\",\n",
    "        \"Purity\": \"sanctity\",\n",
    "        \"Authority\": \"authority\",\n",
    "        \"Loyalty\": \"loyalty\",\n",
    "        \"Proportionality\": \"fairness\",\n",
    "        \"Equality\": \"fairness\"\n",
    "    }\n",
    "    for i, row in tqdm(mfrc.iterrows(), dynamic_ncols=True):\n",
    "        text, fs = row[\"text\"], row[\"annotation\"].split(\",\")\n",
    "        for f in fs:\n",
    "            mfrc_unique.loc[text, key_map[f]] += 1\n",
    "\n",
    "    # Save\n",
    "    mfrc_unique[\"sentence\"] = mfrc_unique.index\n",
    "    mfrc_unique.index = range(len(mfrc_unique))\n",
    "    mfrc_unique.to_csv(\"data/corpora/MFRC_AITA_tokenized.csv\")\n",
    "mfrc_unique = pd.read_csv(\"data/corpora/MFRC_AITA_tokenized.csv\", index_col=0)\n",
    "mfrc_unique[\"tokens\"] = mfrc_unique[\"tokens\"].map(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2644cc0b",
   "metadata": {},
   "source": [
    "## Predict using eMFD scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e76ea9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>care_p</th>\n",
       "      <th>fairness_p</th>\n",
       "      <th>loyalty_p</th>\n",
       "      <th>authority_p</th>\n",
       "      <th>sanctity_p</th>\n",
       "      <th>care_sent</th>\n",
       "      <th>fairness_sent</th>\n",
       "      <th>loyalty_sent</th>\n",
       "      <th>authority_sent</th>\n",
       "      <th>sanctity_sent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>brought</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>-0.235404</td>\n",
       "      <td>-0.310015</td>\n",
       "      <td>-0.099783</td>\n",
       "      <td>-0.402207</td>\n",
       "      <td>-0.13255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         care_p  fairness_p  loyalty_p  authority_p  sanctity_p  care_sent  \\\n",
       "word                                                                         \n",
       "brought    0.18    0.114286       0.08     0.096552    0.053333  -0.235404   \n",
       "\n",
       "         fairness_sent  loyalty_sent  authority_sent  sanctity_sent  \n",
       "word                                                                 \n",
       "brought      -0.310015     -0.099783       -0.402207       -0.13255  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load eMFD lexicon\n",
    "emfd = pd.read_csv(\"emfd/data/eMFD_wordlist.csv\", index_col=\"word\")\n",
    "emfd.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b33fae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(X):\n",
    "    \"\"\"\n",
    "    Average the weights of all tokens with respect to each foundation.\n",
    "    args:\n",
    "        X: either a string or a list of tokens\n",
    "    \"\"\"\n",
    "    foundations = [\"authority_p\", \"care_p\", \"fairness_p\", \"loyalty_p\", \"sanctity_p\"]\n",
    "    if type(X) == str:\n",
    "        X = preprocess(X)\n",
    "    scores = pd.Series(0, index=foundations)\n",
    "    count = 0\n",
    "    for tok in X:\n",
    "        if tok in emfd.index:\n",
    "            count += 1\n",
    "            scores[foundations] += emfd.loc[tok, foundations]\n",
    "    scores.index = [s.split(\"_\")[0] for s in scores.index]\n",
    "    if count > 0:\n",
    "        return scores / count\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69a0561c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17886/17886 [04:24<00:00, 67.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Predict on \n",
    "foundations = [\"authority\", \"care\", \"fairness\", \"loyalty\", \"sanctity\"]\n",
    "scores_df = pd.DataFrame(0, index=mfrc_unique.index, columns=foundations)\n",
    "scores_df[\"tokens\"] = mfrc_unique[\"tokens\"]\n",
    "for i in tqdm(scores_df.index, dynamic_ncols=True):\n",
    "    scores_df.loc[i, foundations] = score(scores_df.loc[i, \"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe7c5710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authority</th>\n",
       "      <th>care</th>\n",
       "      <th>fairness</th>\n",
       "      <th>loyalty</th>\n",
       "      <th>sanctity</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.114044</td>\n",
       "      <td>0.094246</td>\n",
       "      <td>0.087567</td>\n",
       "      <td>0.102482</td>\n",
       "      <td>0.122693</td>\n",
       "      <td>[particular, debate, especially, funny, explai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.078366</td>\n",
       "      <td>0.098072</td>\n",
       "      <td>0.094540</td>\n",
       "      <td>0.086048</td>\n",
       "      <td>0.077889</td>\n",
       "      <td>[pretty, lively, lingo, usually, deliberately,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[closet, fascist, flamboyant, extroverted, fas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.111523</td>\n",
       "      <td>0.093177</td>\n",
       "      <td>0.116527</td>\n",
       "      <td>0.093710</td>\n",
       "      <td>0.106972</td>\n",
       "      <td>[unusual, situation, fillon, affair, influenci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.127654</td>\n",
       "      <td>0.116325</td>\n",
       "      <td>0.105093</td>\n",
       "      <td>0.138541</td>\n",
       "      <td>0.129456</td>\n",
       "      <td>[brand, conservatism, classical, right, wing, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   authority      care  fairness   loyalty  sanctity  \\\n",
       "0   0.114044  0.094246  0.087567  0.102482  0.122693   \n",
       "1   0.078366  0.098072  0.094540  0.086048  0.077889   \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.111523  0.093177  0.116527  0.093710  0.106972   \n",
       "4   0.127654  0.116325  0.105093  0.138541  0.129456   \n",
       "\n",
       "                                              tokens  \n",
       "0  [particular, debate, especially, funny, explai...  \n",
       "1  [pretty, lively, lingo, usually, deliberately,...  \n",
       "2  [closet, fascist, flamboyant, extroverted, fas...  \n",
       "3  [unusual, situation, fillon, affair, influenci...  \n",
       "4  [brand, conservatism, classical, right, wing, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bc1375",
   "metadata": {},
   "source": [
    "Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0edae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "foundations = [\"authority\", \"care\", \"fairness\", \"loyalty\", \"sanctity\"]\n",
    "for foundation in foundations:\n",
    "    y_true = (mfrc_unique[foundation] > 0).astype(int).tolist()\n",
    "    y_score = scores_df[foundation].tolist()\n",
    "    # Naive thresholding\n",
    "    y_pred = (y_score > np.median(y_score)).astype(int).tolist()\n",
    "    \n",
    "    evals = {\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"y_score\": y_score\n",
    "    }\n",
    "    \n",
    "    with open(f\"data/MFRC/eval_results/emfd_{foundation}.json\", \"w\") as f:\n",
    "        json.dump(evals, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b8b21",
   "metadata": {},
   "source": [
    "## Predict using logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72244b9e",
   "metadata": {},
   "source": [
    "Embed the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccbfc743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer,\n",
    "    TfidfVectorizer,\n",
    "    TfidfTransformer\n",
    ")\n",
    "from scipy.sparse import save_npz, load_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "953d95bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf\n",
    "if not os.path.isfile(\"data/MFRC/embeddings/tfidf.npz\"):\n",
    "    sentences = mfrc.text.unique()\n",
    "    tokens = mfrc_unique.tokens\n",
    "\n",
    "    # tfidf\n",
    "    with open(\"emfd/data/embeddings/tfidf_vocab.pkl\", \"rb\") as f:\n",
    "        tfidf_vocab = pickle.load(f)\n",
    "    tfidf_vec = TfidfVectorizer(tokenizer=lambda tokens: tokens, \n",
    "                                lowercase=False, stop_words=None,\n",
    "                                min_df=3, \n",
    "                                max_df=0.99,\n",
    "                                vocabulary=tfidf_vocab\n",
    "                                )\n",
    "    X_tfidf = tfidf_vec.fit_transform(tokens)\n",
    "    save_npz(\"data/MFRC/embeddings/tfidf.npz\", X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ac00b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy\n",
    "if not os.path.isfile(\"data/MFRC/embeddings/spacy_300.npz\"):\n",
    "    X_spacy = np.zeros((len(sentences), 300), dtype=float)\n",
    "    for i, doc in tqdm(enumerate(nlp.pipe(sentences, n_process=-1))):\n",
    "        X_spacy[i, :] = doc.vector\n",
    "    np.savez(\"data/MFRC/embeddings/spacy_300.npz\", X_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9a059b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove\n",
    "if not os.path.isfile(\"data/MFRC/embeddings/glove_twitter_200.npz\"):\n",
    "    from utils import make_one_concept\n",
    "    from gensim.models import KeyedVectors\n",
    "    # load the Stanford GloVe model\n",
    "    glove_filename = \"data/embeddings/glove.twitter.27B.200d\"\n",
    "    word2vec_output_file = glove_filename+'.word2vec'\n",
    "    glove = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
    "    X_glove = np.zeros((len(sentences), 200))\n",
    "    for i, doc in tqdm(enumerate(nlp.pipe(sentences, n_process=-1)), \n",
    "                       desc=\"Processed\", disable=False, \n",
    "                       dynamic_ncols=True, unit=\" docs\"):\n",
    "        tokens = [tok.lemma_.lower() for tok in doc]\n",
    "        X_glove[i] = make_one_concept(model=glove, word_list=tokens,\n",
    "                                    normalize=True)\n",
    "    np.savez(\"data/MFRC/embeddings/glove_twitter_200.npz\", X_glove)\n",
    "    del glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f807b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"data/MFRC/embeddings/sentence_roberta.npz\"):\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    model = SentenceTransformer(\"stsb-roberta-large\")\n",
    "    model.to(\"cuda\")\n",
    "\n",
    "    X_bert = model.encode(sentences)\n",
    "    np.savez(\"data/MFRC/embeddings/sentence_roberta.npz\", X_bert)\n",
    "    del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c03cca",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdb427d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer,\n",
    "    TfidfVectorizer,\n",
    "    TfidfTransformer\n",
    ")\n",
    "\n",
    "with open(\"emfd/data/embeddings/tfidf_vocab.pkl\", \"rb\") as f:\n",
    "    tfidf_vocab = pickle.load(f)\n",
    "\n",
    "embs = {\n",
    "    \"tfidf\": load_npz(\"data/MFRC/embeddings/tfidf.npz\"),\n",
    "    \"spacy\": np.load(\"data/MFRC/embeddings/spacy_300.npz\")[\"arr_0\"],\n",
    "    \"bert\": np.load(\"data/MFRC/embeddings/sentence_roberta.npz\")[\"arr_0\"],\n",
    "    \"glove\": np.load(\"data/MFRC/embeddings/glove_twitter_200.npz\")[\"arr_0\"]\n",
    "}\n",
    "def get_model_and_data(emb_name, foundation):\n",
    "    # Load model\n",
    "    model_name = f\"logreg_{emb_name}_{foundation}\"\n",
    "    model_path = f\"emfd/data/sentence_classifiers/{model_name}.pkl\"\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    model.set_params(**{\"n_jobs\": -1})\n",
    "    \n",
    "    # Load data\n",
    "    X = embs[emb_name]\n",
    "    if foundation == \"none\":\n",
    "        y = np.array(mfrc_unique[[\"care\", \"authority\", \"fairness\", \"loyalty\", \"sanctity\"]].max(1) == 0, dtype=int)\n",
    "    else:\n",
    "        y = (mfrc_unique[foundation] > 0).astype(int)\n",
    "    \n",
    "    return model, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf36cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "foundations = [\"authority\", \"care\", \"fairness\", \"loyalty\", \"sanctity\", \"none\"]\n",
    "emb_names = [\"tfidf\", \"spacy\", \"bert\", \"glove\"]\n",
    "for emb_name in emb_names:\n",
    "    for foundation in foundations:\n",
    "        model, X, y = get_model_and_data(emb_name=emb_name, foundation=foundation)\n",
    "        y_true = y.tolist()\n",
    "        y_score = model.predict_proba(X)[:, 1].tolist()\n",
    "        y_pred = model.predict(X).tolist()\n",
    "\n",
    "        evals = {\n",
    "            \"y_true\": y_true,\n",
    "            \"y_pred\": y_pred,\n",
    "            \"y_score\": y_score\n",
    "        }\n",
    "        \n",
    "        model_name = f\"logreg_{emb_name}_{foundation}\"\n",
    "        \n",
    "        with open(f\"data/MFRC/eval_results/{model_name}.json\", \"w\") as f:\n",
    "            json.dump(evals, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa713ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a83c7f9c0b00199977994ef8b792d191275126a21078cfa6a3899708a2d04dc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
